---
title: '<span style="font-size:48pt;">Fitting Models</span>'
subtitle: 'üìà  üíª  ü§ñÔ∏è' 
author: 'Applied Machine Learning in R <br />Pittsburgh Summer Methodology Series'
date: 'Day 1D &emsp; &emsp; August 8, 2022'
output:
  xaringan::moon_reader:
    css: [../xaringan-themer.css, ../styles.css]
    nature:
      slideNumberFormat: "%current% / %total%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: false
      navigation:
        scroll: false
    self_contained: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  fig.showtext = TRUE,
  out.width = "100%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE,
  comment = "#>",
  collapse = TRUE
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
```

```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_tachyons()
xaringanExtra::use_clipboard()
```

```{r packages, echo=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(countdown)
library(patchwork)
```

class: inverse, center, middle
# Overview

---
class: onecol
## Plan for Today

First will be a lecture focusing on .imp[training models and making predictions] in R.

All modeling will be done with **{parsnip}**, part of the {tidymodels} meta-package.

Specifically, we will learn to `fit()` and `predict()` models with a common interface.

--

<p style="padding-top:30px;"> We will end with a **live coding activity**. 

This will put everything we have learned today into practice. 

We will build a basic model and use it to predict out-of-sample testing data.

This will ease the transition to full ML {workflows}, which we will learn tomorrow.

---
class: onecol
## Motivation

Suppose we have collected data that are now ready to be fit to a statistical model. 

Let's say that a linear regression model is our first choice: 

$$y_i = \beta_0 + \beta_1x1_i+...+\beta_px_{pi}$$
--

There are **many statistical methods available** for estimating these model parameters:
- Ordinary least squares (OLS) regression 

- Regularized linear regression<sup>1</sup>, such as lasso, ridge, and elastic net regression.

.footnote[
[1] No need to be familiar with regularization yet; we will learn about these algorithms in detail on Day 3! 
]

--

<p style="padding-top:30px;">However, they use different R packages with **varying syntax, arguments, and output**. 

---
class: onecol
## A Problem

The {stats} package implements **OLS regression** using .imp[formula notation], with data accepted in a dataframe or vector.

```{r, eval = FALSE}
model <- lm(outcome ~ predictor, data = df, ...)
```

--

<p style="padding-top:30px;"> The {glmnet} package implements **regularized regression** using .imp[x/y notation], with predictors required to be formatted as a numeric matrix and the outcome as a vector.

```{r, eval = FALSE}
model <- glmnet(x = outcome, y = predictor, ...)
```

--

<p style="padding-top:30px;"> This makes it a **pain** to switch between models! 

---
class: onecol
## A Problem

R packages also return **model predictions** in different formats. 

Some examples of these inconsistencies for various classification models:

--

.center[
```{r, echo = FALSE, out.width = "40%"}
include_graphics("../figs/package_predictions.png")
```
]

---
class: twocol
## A Solution

.left-column[
<br />
```{r, echo = FALSE}
include_graphics("../figs/parsnip.png")
```
]

--

.right-column[
The {parsnip} package provides a **unified interface** for model fitting.

There are functions to:
- Specify models
- Fit models 
- Inspect model results
- Make predictions

We can fit any model with the **same syntax and data format**.

We **don't need memorize** specific details of any particular R package!
]

---
class: inverse, center, middle
# Introduction to {parsnip}

---
## A {parsnip} roadmap
</br>

```{r, echo = FALSE}
include_graphics("../figs/parsnip_workflow.png")
```

---
class: onecol
## 1. Specify Model Details

Before fitting an ML model, we need to **specify the model details**.

--

<p style="padding-top:30px;">All models are specified with the same **syntactical structure** in {parsnip}.

- **Model Type**: the mathematical structure (e.g., linear regression, random forests)

- **Model Mode**: the mode of prediction (e.g., regression, classification)<sup>1</sup>.

- **Computational Engine**: how the actual model is fit (often a specific R package)

.footnote[
[1] Sometimes the model mode is already determined by the model type (e.g., linear regression) and so specifying a mode is not needed.
]

--

<p style="padding-top:30px;">These details are specified *before* even referencing the data. 


---
class: onecol
## Example: OLS Regression

To specify an OLS regression in {parsnip}, we specify<sup>1</sup>:
- The model type as `linear_reg()` 
- The computational engine as `"lm"`.

.footnote[
[1] We don't need to specify the model mode because `linear_reg()` already implies `mode = regression`. 
]

--

```{r}
library(tidymodels)
tidymodels_prefer()

ols_reg <- linear_reg() %>% # specify model type
  set_engine("lm") # specify computational engine
ols_reg
```

---
class: onecol 
## Example: Regularized Regression

If we want to use regularization, we simply change the **computational engine**. 

--

```{r}
# specify a GLMNET regression
glmnet_reg <- linear_reg() %>% 
  set_engine("glmnet") 

glmnet_reg
```

--

Switching between OLS vs. regularization is now much simpler! 

---
class: onecol 
## Model Tuning

Some algorithms (such as regularized regression) have *hyperparameters*<sup>1</sup>.

We can change hyperparameters to find the value that optimizes model performance.

However, might not know what the best value is just yet.

This is the basis of **model tuning**, which can be included when specifying model type.

.footnote[
[1] e.g., `linear_reg` has a `penalty` hyperparameter that sets the degree of regularization. We will learn about hyperparameters and tuning in detail on Day 3, so no need to worry about the details yet! 
]

--

.scroll25[
```{r}
glmnet_tune <- linear_reg(penalty = tune()) %>% set_engine("glmnet")
glmnet_tune
```
]

---
class: onecol
## More Model Type Arguments

To see all arguments for a particular model type, use `args()`.

--

```{r}
args(linear_reg)
```

--

```{r}
args(rand_forest)
```


---
class: onecol
## More Computational Engines 

To see all the computational engines that exist for a model type, use `show_engines()`. 

--

.pull-left[
```{r, eval = FALSE}
show_engines("linear_reg")
```

```{r, echo = FALSE}
show_engines("linear_reg") %>% kable() %>% kable_styling(position = "left") %>% scroll_box(height = "300px")
```
]

--

.pull-right[
```{r, eval = FALSE}
show_engines("rand_forest")
```

```{r, echo = FALSE}
show_engines("rand_forest") %>% kable() %>% scroll_box(height = "300px")
```
]

---
class: onecol 
## A World of Possibilities

There are **hundreds** of machine learning models available in {parsnip}.

Many models can be implemented in different ways (different computational engines).

You can explore all the options on the [tidymodels website](https://www.tidymodels.org/find/parsnip/).

--

<p style="padding-top:30px;">To fit different ML models, you just change the **model type** and `set_engine()`.

This makes it *super* easy to implement new algorithms and explore the world of ML!

--

.bg-light-yellow.b--light-red.ba.bw1.br3.pl4[
**Caution:** Be sure you understand an algorithm before writing a paper with it.
]

---
class: onecol
## 2. Fit Model

Once we have specified model details, we can fit the model using the `fit()` function.

Let's walk through an OLS example with some pseudocode. 

--

```{r, eval = FALSE}
ols_reg <- linear_reg() %>% 
  set_engine("lm") 

ols_reg_fit <- ols_reg %>% 
  fit(outcome ~ predictor, data = my_data)
```

--

In {parsnip}, models can be flexibly fit with **formula notation** or **x/y notation**. 

```{r, eval = FALSE}
ols_reg_fit <- ols_reg %>% 
  fit_xy(x = select(my_data, predictor), y = select(my_data, outcome))
```

---
class: onecol 
## 3. Inspect Model Results

Once we fit a model, we can examine the model by printing or plotting it.

Some useful functions:

- `tidy()`: return model summary (coefficient values, std error, *p* value) in a tibble

- `glance()`: return performance metrics from the training data (e.g., $r^2$)

- `vip()`: variable importance plots (note: from a separate {vip} package)

- `autoplot()`: plot tuning search results (relevant when working with hyperparameters)

---
class: onecol
## 4. Make Model Predictions 

Getting predictions for `parsnip` models is easy and *tidy* with `predict()`:

Argument&emsp; | Description
:------- | :----------
object | A trained model object created by `fit()`
new_data | A data frame with the same features as training
type | Data type (numeric, classes, probabilities, etc.)

---
class: onecol
## 4. Make Model Predictions

The `predict()` function will always return: 

- Predictions as a tibble

- The same number of rows as the data being predicted 

- Interpretable column names (e.g., `.pred`, `.pred_lower`, `.pred_upper`)

--

.bg-light-green.b--dark-green.ba.bw1.br3.pl4[
These rules make it easier to merge predictions with the original data!
]

---
class: onecol
## Summary

Today started with a **conceptual overview** of the goals and methods of ML.

We reviewed **tidyverse** principles and datasets used in the course. 

We introduced the basic goals of **data splitting** with {rsample}.

Finally, we fit and evaluated our first **prediction model** with {parsnip}.

--

<p style="padding-top:30px;"> Tomorrow will dive into **feature engineering** and **performance evaluation**.

We will also learn more advanced **cross-validation** for a full ML **workflow**.

---
class: inverse, center, middle
# Live Coding


---
class: inverse, center, middle
# End of Day 1

