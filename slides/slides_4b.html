<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Practical Issues</title>
    <meta charset="utf-8" />
    <meta name="author" content="Pittsburgh Summer Methodology Series" />
    <script src="slides_4b_files/header-attrs/header-attrs.js"></script>
    <link href="slides_4b_files/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="slides_4b_files/clipboard/clipboard.min.js"></script>
    <link href="slides_4b_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="slides_4b_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="slides_4b_files/countdown/countdown.css" rel="stylesheet" />
    <script src="slides_4b_files/countdown/countdown.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <span style="font-size:48pt;">Practical Issues</span>
]
.subtitle[
## .big[üé® üî¨ üìùÔ∏è]
]
.author[
### Pittsburgh Summer Methodology Series
]
.date[
### Day 4B ‚ÄÉ ‚ÄÉ August 11, 2022
]

---










class: inverse, center, middle
# Overview

---
class: onecol
## Lecture Topics

This lecture will cover some **practical issues** involved in applied ML research. 

We will also highlight **advanced topics** for future learning beyond this course. 

We will discuss:

- Considerations for study design 

- Selecting and comparing algorithms 

- Bias, justice, and representativeness 

- Critically evaluating results from ML models

- Reading &amp; reviewing ML papers 

---
class: inverse, center, middle
# Designing Studies

---
class: onecol
## Back to Basics

The goal of supervised ML is to .imp[predict values] of important variables in new data. 

We focus less on **inference** (e.g., finding features that significantly predict outcomes).

**Features** used to predict tend to be cheaper or easier to measure in new data. 

**Outcomes** to be predicted tend to be expensive or difficult to measure in new data. 

ML models can be used for both **regression and classification** problems.

---
class: onecol
## Asking Predictive Questions 

As social &amp; behavioral scientists, we aim to **explain and predict** behavior. 

An implicit assumption is that better explanation will lead to better prediction. 

However, statistically, this is not always the case (e.g., due to **overfitting**).

Shifting from an **explanatory/inferrential** mindset to a **predictive** mindset isn't easy! 

.footnote[
I highly recommend Yarkoni &amp; Westfall (2017), Choosing Prediction over Explanation in Psychology: Lessons from Machine Learning. https://journals.sagepub.com/doi/10.1177/1745691617693393
]

---
class: onecol
## Asking Predictive Questions

**Question: Can we infer people's personalities from their social media usage?**

- *Inferential mindset*: test for statistically significant relationships between personality dimensions and other variables  (e.g., ratings of someone's Twitter profile).

- *Predictive mindset*: build an ML model with the goal of predicting someone's scores on a personality measure from social media data. 

--

&lt;p style="padding-top:30px;"&gt;**Question: How likely is someone to recover from an anxiety disorder?**

- *Inferential mindset*: identify variables at time 1 that have a statistically significant relationship with recovery at time 2.

- *Predictive mindset*: build an ML model with the goal of using time 1 data to accurately predict anxiety scores at time 2.

---
class: onecol
## Cause and Effect

Machine learning is a **data-driven method**.

However, this does not mean that it is **atheoretical**.

--

&lt;p style="padding-top:30px;"&gt;Strong understanding of underlying causal structure of our variables is still important.

Models are more accurate if features are **causes** rather than **effects** of the outcome&lt;sup&gt;1&lt;/sup&gt;.

Design of ML studies should be driven by strong theory

.footnote[
[1] See Piccininni et al. (2020) for theoretical explanation and simulation results: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01058-z
]

---
class: onecol
## Measurement

*"Throwing the same set of poorly measured variables that have been analyzed before into machine learning algorithms is highly unlikely to produce new insights or findings."&lt;sup&gt;1&lt;/sup&gt;*

.footnote[
[1] Jacobucci &amp; Grimm (2020); *Perspectives on Psychological Science* &lt;/br&gt;
[2] Flake &amp; Fried (2020); *Advances in Methods and Practices in Psychological Science*
]

--

&lt;p style="padding-top:30px;"&gt;**Questionable measurement practices**&lt;sup&gt;2&lt;/sup&gt; include: 

- Unclear definitions of constructs

- Lack of reliability and validity of measures 

- Using scales in ways they were not intended 

--

&lt;p style="padding-top:30px;"&gt;Measurement error can prevent ML from accurately modeling nonlinear relationships. 

---
class: onecol
## Measurement

&lt;img src="../figs/qmps.png" width="85%" /&gt;

.footnote[
Flake &amp; Fried (2020); *Advances in Methods and Practices in Psychological Science*
]

---
class: onecol
## Sample Size

One of the most common questions we hear is .imp["how much data do I need for ML"?] 

There's no straightforward or universal answer, and this is an active area of research.

However, here are some important principles and general guidelines.

--

&lt;/br&gt;
When working with smaller sample sizes, use simpler models.

Use k-fold CV on the full dataset for smaller samples rather than one held-out test set. 

Better yet, use nested CV for smaller samples! 

---
class: onecol
## Bias and Representativeness

Algorithms are often heralded as 'objective'. 

However, even ML algorithms reflect the nature of the data used to train them.

ML can .imp[detect, learn, and perpetuate societal injustices] if we are not careful.

--

&lt;p style="padding-top:30px;"&gt;For example: 

- Chatbots trained on internet data produce sexist &amp; racist responses

- Recidivism algorithms are biased against Black defendants 

- Facial recognition works better for White people than people of color 

- STEM advertisements are less likely to be displayed to women than men

---
class: onecol
## Bias and Representativeness 

.pull-left[
&lt;img src="../figs/huggingface_man.png" width="96%" style="display: block; margin: auto 0 auto auto;" /&gt;
]
.pull-right[
&lt;img src="../figs/huggingface_woman.png" width="100%" style="display: block; margin: auto auto auto 0;" /&gt;
]

---
class: onecol
## Bias and Representativeness

Training a model with .imp[biased data] will produce .imp[biased predictions].

When designing a study, pay attention to who is included in the sample &amp; who is left out.

--

&lt;p style="padding-top:30px;"&gt;Critically evaluate the features and labels you're collecting. 

- Are they equally valid and reliable for all groups of people? 

- Are they accurate and sensitive at assessing the outcome for everyone?

---
class: inverse, center, middle
## Modeling Decisions

---
class: twocol
## Choosing an Algorithm 

Algorithm&amp;emsp; | Benefits | Drawbacks 
:------- | :-------- | :------- 
Ridge | handles multicollinearity; shrinks correlated features together | does not perform feature selection; does not model nonlinearity
Lasso | handles multicollinearity; performs feature selection | tends to pick one correlated feature &amp; ignore the rest; does not model nonlinearity
Elastic Net | Ridge-like regression with lasso-like feature selection | does not model nonlinearity 
Decision Trees | easily interpretable; models nonlinearity | unstable; poor prediction in new datasets (not often used in practice) 
Random Forests | models nonlinearity, good prediction in new data | not easily interpretable, requires larger sample sizes  
SVM | can handle `\(p&gt;n\)`; models nonlinearity  | not easily interpretable; can be difficult to choose a 'good' kernel function

---
class: onecol
## Algorithm Assumptions 

Algorithm&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp; | Assumptions 
:------- | :-------- 
Ridge / Lasso / Elastic Net| Linear relationship between features and outcome. Features should be on the same scale (normalize!). Dummy code nominal features.
Decision Trees / Random Forests | No formal assumptions; they are non-parametric. Features don't have to be on the same scale. One-hot encoding of nominal features. 
SVM | Features should be on the same scale (normalize!). Dummy code nominal features. 

&lt;/br&gt; 
Note: unlike familiar statistical methods (e.g., linear regression models), these methods have no distributional assumptions about error terms. 

---
class: inverse, center, middle
# Critically Evaluating Results

---
class: onecol
## What is "Good" Accuracy? 

Not all performance metrics are equally informative for all prediction problems. 

Consider your ultimate use case - what is most important for your model?

- Is it more important to detect **true positives**? 

- Is it more important to avoid **false negatives**? 

- Are your data imbalanced?

These goals may differ across different modeling problems.

---
class: onecol
## Can you Trust your Model? 

An ML model can always provide a prediction, given input features. 

However, in some situations it is not appropriate to make such predictions:

- If a new data point is outside the range of training data 

- If a model was trained for a different context 

- If the data-generating process changes from model training to deployment

---
class: onecol
## Can you Trust your Model? 

In some cases, the amount of .imp[uncertainty] is also too high for us to trust a prediction. 

Recall that many classification models use 0.50 as a decision boundary between classes.

--

&lt;p style="padding-top:30px;"&gt;Imagine you took a COVID test and it comes back positive (predicted class = 1). 

But, imagine you then learn the *predicted probability* was only 0.51.

Would you trust the prediction from this COVID test? 

--

&lt;p style="padding-top:30px;"&gt;**Equivocal zones**&lt;sup&gt;1&lt;/sup&gt; can help index if uncertainty is too high for predictions to trusted. 

These can be set manually (e.g., 0.50 `\(\pm\)` 0.15) or based on standard errors.

.footnote[
[1]See more on the tidymodels website: https://www.tmwr.org/trust.html.
]

---
class: onecol
## Importance of External Validation

Throughout this course, we have learned methods for **internal cross-validation**.

However, .imp[external validation] remains the gold standard for evaluating ML models. 

--

.pull-left[
&lt;img src="../figs/covid.png" width="100%" /&gt;
]

--

.pull-right[
ML models have been very popular in predicting COVID-19 outcomes. 

Many papers made impressive claims about predictive accuracy.

However, when 22 published ML models were tested on new data, *none* beat simple univariate predictors.
]

---
class: inverse, center, middle
# Reading and Reviewing ML Papers 

---
class: onecol
## Peer-Reviewing ML Papers 

ML papers in psychology (and other social/behavioral sciences) are .imp[rapidly increasing].

Often, this feels like a double-edged sword. 

- On one hand, ML methods can help solve many problems we care about.

- On the other, some papers may not be high-quality.

- People may rush to publish before fully understanding their models.

--

&lt;p style="padding-top:30px;"&gt;Either way, this means there are **many papers that need to be reviewed!**

As responsible ML practitioners, you should be well-equipped to review these papers.

Here are some aspects to pay attention to when reviewing ML papers. 

---
class: twocol
## Is the Sample Appropriate? 

.left-column.pv3[
&lt;img src="../figs/sample.jpg" width="100%" /&gt;
]

.right-column[
**As a reader/reviewer, consider:** 

- Is the sample is representative of the population?

- Will a model trained on this sample generalize to future use cases?

- Are any groups under- or over-represented in the sample? 

- Is sample size adequate (given their specific modeling methods)?

- Is the sample well-suited for answering the research question? 
]

---
class: twocol
## Measurement and Feature Engineering

.left-column.pv3[
&lt;img src="../figs/engineer.jpg" width="100%" /&gt;
]

.right-column[
**As a reader/reviewer, consider:** 

- Measurement (and justification) of features and labels

- Rationale for and clear description of feature engineering

- Appropriate feature engineering to match specific algorithms (e.g., normalizing features for regularized regression)

- Clear description of missing data and missing data handling (e.g., listwise deletion vs imputation)
]

---
class: twocol 
## Resampling and Data Leakage

.left-column.pv3[
&lt;img src="../figs/leak.jpg" width="100%" /&gt;
]

.right-column[
**As a reader/reviewer, consider:** 

- Is there clear separation between model training vs. evaluation? 

- Is there any evidence of data leakage?

- Adequate size of test sets during resampling 

- Understanding of limitations of resampling methods

- Appropriate handling of multilevel/nested data (if applicable)

- Appropriate handling of time series data (if applicable)
]

---
class: twocol 
## Model Evaluation and Interpretation

.left-column.pv3[
&lt;img src="../figs/target.jpg" width="100%" /&gt;
]

.right-column[
**As a reader/reviewer, consider:** 

- Are interpretations and claims supported by the modeling methods?

- Are evaluation metrics differentiated appropriately (e.g., accuracy vs. AUROC vs. sensitivity vs. specificity)?

- Appropriate interpretation of performance

- Not overstating performance 

- Limitations adequately stated 
]


---
class: inverse, center, middle
# Time for a Break!
<div class="countdown" id="timer_62f1b261" style="right:33%;bottom:15%;left:33%;" data-warnwhen="60">
<code class="countdown-time"><span class="countdown-digits minutes">60</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current% / %total%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false,
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
